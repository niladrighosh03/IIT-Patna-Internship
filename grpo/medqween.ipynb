{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b976324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/rohan_kirti/miniconda3/envs/nilenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset, Dataset, interleave_datasets, concatenate_datasets\n",
    "\n",
    "# Load and prep dataset\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "# uncomment middle messages for 1-shot prompting\n",
    "def get_datasets(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
    "    data = data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer']),\n",
    "        'db_set':'gsm8k'\n",
    "    }) # type: ignore\n",
    "    data = data.remove_columns(['question'])\n",
    "\n",
    "    data_qa = load_dataset(\"qiaojin/PubMedQA\", \"pqa_artificial\")[split] # two times more than other datasets\n",
    "    data_qa = data_qa.filter(lambda x: len(\"\\n\".join(x['context']['contexts'])) < 1024) # avoid long traces\n",
    "    data_qa = data_qa.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Given the scientific context below:\\n\" +\n",
    "                          \"\\n\".join(x['context']['contexts']) +\n",
    "                          \"\\n\\nAnswer the following question:\\n\" +\n",
    "                          x['question'] +\n",
    "                          \" with 'yes', 'no' or 'maybe'. You need to carefully review the context and reason before answering.\"\n",
    "            },\n",
    "        ],\n",
    "        'answer': x['final_decision'],\n",
    "        'db_set': 'pubmedqa'\n",
    "    }) # type: ignore\n",
    "    data_qa = data_qa.remove_columns(['pubid', 'question', 'context', 'long_answer', 'final_decision'])\n",
    "\n",
    "\n",
    "    categories =['Lab_Medicine', 'Wearables', 'Dermatology', 'Gastroenterology', 'Internal_Medicine', 'Oncology', 'Orthopedics', 'General_Surgery', 'Ophthalmology', 'Audiology', 'Head_Neck_Surgery', 'Elderly_Care', 'Pediatrics', 'Allergy_Immunology', 'Rheumatology', 'Pharmacy', 'Obstetrics_Gynecology', 'Microbiology', 'Dentistry', 'Physical_Medicine_and_Rehabilitation', 'Neurology', 'Psychiatry', 'Pathology', 'Genetics', 'Rare_Diseases', 'Hematology', 'Emergency', 'Endocrinology', 'Radiology', 'Cardiology', 'Pulmonology', 'Infectious_Diseases', 'Critical_Care', 'Pediatric_Surgery', 'Neuroscience', 'Epidemiology', 'Fitness_Sports', 'Health_Education', 'Health_Economics', 'Health_Entrepreneurship', 'Hospital_Management', 'Mental_Health', 'Nutrition', 'Palliative_Care', 'Preventive_Medicine', 'Public_Health', 'Social_Media_Addiction', 'Sleep', 'Supplements', 'Vaccination', 'Work_Health', 'Wellbeing']\n",
    "    data_mc = concatenate_datasets([load_dataset(\"yesilhealth/Health_Benchmarks\",i)[i] for i in categories])\n",
    "    data_mc = data_mc.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\\n\\nAnswer the following question:\\n\" +\n",
    "                          x['Questions'] +\n",
    "                          \"\\n With 'A', 'B', 'C' or 'D'. You need to carefully review the context and reason before answering.\"\n",
    "            },\n",
    "        ],\n",
    "        'answer': x['Answers'],\n",
    "        'db_set': 'med_mc'\n",
    "    }) # type: ignore\n",
    "    data_mc = data_mc.remove_columns(['Answers', 'Questions'])\n",
    "\n",
    "    dataset = concatenate_datasets([data, data_qa, data_mc])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76a0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_datasets()\n",
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892a0eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'no',\n",
      " 'db_set': 'pubmedqa',\n",
      " 'prompt': [{'content': '\\n'\n",
      "                        'Respond in the following format:\\n'\n",
      "                        '<reasoning>\\n'\n",
      "                        '...\\n'\n",
      "                        '</reasoning>\\n'\n",
      "                        '<answer>\\n'\n",
      "                        '...\\n'\n",
      "                        '</answer>\\n',\n",
      "             'role': 'system'},\n",
      "            {'content': 'Given the scientific context below:\\n'\n",
      "                        'To define the role of dopamine-2 receptors in the '\n",
      "                        'sympatho-inhibitory effects of '\n",
      "                        'gamma-l-glutamyl-l-dopa in conscious rabbits.\\n'\n",
      "                        'gamma-l-glutamyl-l-dopa (gludopa) was infused iv at '\n",
      "                        '25 and 100 micrograms.kg-1.min-1 with and without '\n",
      "                        'prior dopamine-2 receptor blockade by YM-09151-2 (50 '\n",
      "                        'micrograms.kg-1 iv) in conscious rabbits.\\n'\n",
      "                        'Mean arterial pressure and heart rate remained '\n",
      "                        'unchanged while renal plasma flow increased. Arterial '\n",
      "                        'norepinephrine (NE) concentration, total and renal NE '\n",
      "                        'spillover rate were markedly decreased in a '\n",
      "                        'dose-related manner, which were not affected by prior '\n",
      "                        'dopamine-2 receptor blockade. Gludopa was detected in '\n",
      "                        'the whole brain (92 +/- 112 ng/g wet brain tissue) at '\n",
      "                        'the end of experiment although brain tissue levodopa, '\n",
      "                        'NE, and dopamine contents were not much different '\n",
      "                        'from those in the control group.\\n'\n",
      "                        '\\n'\n",
      "                        'Answer the following question:\\n'\n",
      "                        'Are sympatho-inhibitory effects of '\n",
      "                        'gamma-l-glutamyl-l-dopa mediated by activation of '\n",
      "                        'dopamine-2 receptors in conscious rabbits? with '\n",
      "                        \"'yes', 'no' or 'maybe'. You need to carefully review \"\n",
      "                        'the context and reason before answering.',\n",
      "             'role': 'user'}]}\n",
      "--------------------------------------------------\n",
      "{'answer': 'yes',\n",
      " 'db_set': 'pubmedqa',\n",
      " 'prompt': [{'content': '\\n'\n",
      "                        'Respond in the following format:\\n'\n",
      "                        '<reasoning>\\n'\n",
      "                        '...\\n'\n",
      "                        '</reasoning>\\n'\n",
      "                        '<answer>\\n'\n",
      "                        '...\\n'\n",
      "                        '</answer>\\n',\n",
      "             'role': 'system'},\n",
      "            {'content': 'Given the scientific context below:\\n'\n",
      "                        'To determine if hemodynamic profiling using '\n",
      "                        'noninvasive impedance cardiography (ICG) reliably '\n",
      "                        'identifies the patient with severe (SPRE) or '\n",
      "                        'superimposed (SuPRE) preeclampsia.\\n'\n",
      "                        'Late gestation hypertensive pregnant patients '\n",
      "                        'underwent immediate ICG evaluation. Findings were '\n",
      "                        'compared between patients subsequently achieving or '\n",
      "                        'not achieving American College of Obstetricians and '\n",
      "                        'Gynecologists criteria for SPRE or SuPRE.\\n'\n",
      "                        'Patients with severe disease were more likely to have '\n",
      "                        'depressed cardiac function and higher systolic blood '\n",
      "                        'pressure, mean arterial blood pressure, systemic '\n",
      "                        'vascular resistance, and thoracic fluid content '\n",
      "                        'compared to nonsevere hypertensive disease.\\n'\n",
      "                        '\\n'\n",
      "                        'Answer the following question:\\n'\n",
      "                        'Does impedance cardiography facilitate '\n",
      "                        'differentiation of severe and superimposed '\n",
      "                        'preeclampsia from other hypertensive disorders? with '\n",
      "                        \"'yes', 'no' or 'maybe'. You need to carefully review \"\n",
      "                        'the context and reason before answering.',\n",
      "             'role': 'user'}]}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Pretty print the first 5 rows\n",
    "for i in range(2):\n",
    "    pprint(dataset[i])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f763f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(100))  # Take first 100 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12baabde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answer', 'prompt', 'db_set'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55c2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_split = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = small_split[\"train\"]\n",
    "test_dataset = small_split[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d13f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answer', 'prompt', 'db_set'],\n",
       "    num_rows: 90\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c32b36",
   "metadata": {},
   "source": [
    "#### Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0c42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reward functions\n",
    "def correctness_reward_func(prompts, completions, answer, db_set, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    rewards = []\n",
    "    for r,a,dt in zip(extracted_responses, answer, db_set):\n",
    "        if dt == \"gsm8k\":\n",
    "            if a in r:\n",
    "                rewards.append(1.0)\n",
    "            elif r == a:\n",
    "                rewards.append(2.0)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "        else:\n",
    "            rewards.append(2.0 if r.lower() == a.strip().lower() else 0.0)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def int_reward_func(completions, db_set, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    rewards = []\n",
    "    for r,dt in zip(extracted_responses,db_set):\n",
    "        if dt == \"gsm8k\":\n",
    "            rewards.append(0.5 if r.isdigit() else 0.0)\n",
    "        elif dt == \"pubmedqa\":\n",
    "            rewards.append(0.5 if ('yes' in r.lower() or 'no' in r.lower() or 'maybe' in r.lower()) else 0.0)\n",
    "        else:\n",
    "            rewards.append(0.5 if ('a' in r.lower() or 'b' in r.lower() or 'c' in r.lower() or 'd' in r.lower()) else 0.0)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "242651f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd090c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiiuae/falcon-rw-1b\"  # Substitute for a small model (2B unavailable here)\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,device_map=\"auto\")\n",
    "model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ced8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrockbong225\u001b[0m (\u001b[33mrockbong225-iit-patna\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/DATA/rohan_kirti/wandb/run-20250702_183542-o3cblwsz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rockbong225-iit-patna/grpo-training/runs/o3cblwsz' target=\"_blank\">breezy-terrain-14</a></strong> to <a href='https://wandb.ai/rockbong225-iit-patna/grpo-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rockbong225-iit-patna/grpo-training' target=\"_blank\">https://wandb.ai/rockbong225-iit-patna/grpo-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rockbong225-iit-patna/grpo-training/runs/o3cblwsz' target=\"_blank\">https://wandb.ai/rockbong225-iit-patna/grpo-training/runs/o3cblwsz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rockbong225-iit-patna/grpo-training/runs/o3cblwsz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f96bc269a10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class SimpleWandbTableCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and state.epoch is not None:\n",
    "            # Collect the data\n",
    "            row = [\n",
    "                state.global_step,\n",
    "                round(state.epoch, 2),\n",
    "                logs.get('train_loss', 0),\n",
    "                logs.get('rewards/total', logs.get('reward', 0)),\n",
    "                logs.get('learning_rate', 0)\n",
    "            ]\n",
    "            self.data.append(row)\n",
    "            \n",
    "            # Create and log table every few steps\n",
    "            if state.global_step % 1 == 0:  # Log table every step\n",
    "                table = wandb.Table(\n",
    "                    columns=[\"Step\", \"Epoch\", \"Loss\", \"Total Reward\", \"Learning Rate\"],\n",
    "                    data=self.data\n",
    "                )\n",
    "                wandb.log({\"training_table\": table})\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"grpo-training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f6cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate=5e-6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"adamw_8bit\",  # Requires bitsandbytes\n",
    "    logging_steps=1,\n",
    "\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,  # Slightly smoother training\n",
    "    num_generations=2,  # Safe for Falcon-1B\n",
    "    max_prompt_length=512,\n",
    "    max_completion_length=128,\n",
    "    max_steps=5,\n",
    "    save_steps=2,\n",
    "    max_grad_norm=0.1,\n",
    "    # report_to=\"none\",\n",
    "    report_to=\"wandb\", \n",
    "    output_dir=\"outputs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49ba813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3db83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        xmlcount_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        strict_format_reward_func,\n",
    "        int_reward_func,\n",
    "        correctness_reward_func,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    callbacks=[SimpleWandbTableCallback()],\n",
    "    peft_config=peft_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd39298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "Given the scientific context below:\n",
      "To verify whether the long-term retention of an emotionally arousing story is stronger than the retention of a neutral story, and the enhancing effects of emotional arousal on declarative memory in Alzheimer's disease (AD) patients.\n",
      "Twenty subjects (10 with AD and 10 controls matched for age and educational level) were studied. After the audiovisual presentation (neutral story), the subjects rated the narrative's emotionality. Later, they answered a multiple-choice questionnaire about the stories. Two weeks later, they watched the emotionally arousing story.\n",
      "Subjects who watched the emotionally arousing story assigned a score of emotionality higher than the subjects in the neutral group (P = 0.023). In addition, the participants remembered more details of the arousing story, and had a higher score in the questionnaire (P < 0.001).\n",
      "\n",
      "Answer the following question:\n",
      "Does emotional arousal enhance declarative memory in patients with Alzheimer 's disease? with 'yes', 'no' or 'maybe'. You need to carefully review the context and reason before answering. \n",
      "Answer:\n",
      "yes \n",
      "Response:\n",
      "<reasoning>\n",
      "The study presented demonstrates that not only are subjects in the emotionally arousing story condition more likely to assign a higher score to emotional narrative compared to the control group, but they also have better recall of the story details. This is further evidenced by the higher scores on the questionnaire, indicating improved memory retention. Furthermore, a distinction should be made between the AD patients and the controls. Even within the control group of subjects matched for age and educational level, there is a significant difference in the recognition of a story's emotionality and subsequent memory retention. Despite this controlled group comparison, the AD patients performed even better on these measures, \n",
      "Extracted:\n",
      "<reasoning>\n",
      "The study presented demonstrates that not only are subjects in the emotionally arousing story condition more likely to assign a higher score to emotional narrative compared to the control group, but they also have better recall of the story details. This is further evidenced by the higher scores on the questionnaire, indicating improved memory retention. Furthermore, a distinction should be made between the AD patients and the controls. Even within the control group of subjects matched for age and educational level, there is a significant difference in the recognition of a story's emotionality and subsequent memory retention. Despite this controlled group comparison, the AD patients performed even better on these measures,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:35, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "Given the scientific context below:\n",
      "The urinary bladder expresses Ca(2+)-activated Cl(-) channels (CACC), but its physiological role in governing contractility remains to be defined. The CACC modulator niflumic acid (NFA) is widely used despite the variable results arisen from different drug concentrations used. This study was designed to examine the effects of NFA at low concentrations on detrusor strip contractility.\n",
      "Rat detrusor strips with mucosa-intact (+MU) and mucosa-denuded (-MU) were prepared in transverse (Tr) and longitudinal (Lg) with respect to the bladder orientation. Isometric force measurements were made at baseline (for spontaneous phasic contractile activity) and during drug stimulation (by carbachol, CCh) with and without NFA.\n",
      "NFA (1 and 10 μmol/L) pretreatment enhanced CCh-induced contractions more in +MU than -MU strips with no selectivity on contractile direction. For spontaneous phasic contractions, NFA-treated strips in the Tr direction showed increased phasic amplitude, while phasic frequency was unchanged.\n",
      "\n",
      "Answer the following question:\n",
      "Do low concentrations of niflumic acid enhance basal spontaneous and carbachol-induced contractions of the detrusor? with 'yes', 'no' or 'maybe'. You need to carefully review the context and reason before answering. \n",
      "Answer:\n",
      "yes \n",
      "Response:\n",
      "<reasoning>\n",
      "According to the context provided, the effects of niflumic acid (NFA) at low concentrations were examined on rat detrusor strips with different preparations. The study describes NFA’s effects when it was applied before the application of carbachol (CCh) and under physiological conditions, where it is present as spontaneous phasic contractions.\n",
      "\n",
      "From the results:\n",
      "- For CCh-induced contractions: NFA (1 and 10 μmol/L) pretreatment enhanced CCh-induced contractions more in mucosa-intact (+MU) than mucosa-denuded (-MU) strips with no \n",
      "Extracted:\n",
      "<reasoning>\n",
      "According to the context provided, the effects of niflumic acid (NFA) at low concentrations were examined on rat detrusor strips with different preparations. The study describes NFA’s effects when it was applied before the application of carbachol (CCh) and under physiological conditions, where it is present as spontaneous phasic contractions.\n",
      "\n",
      "From the results:\n",
      "- For CCh-induced contractions: NFA (1 and 10 μmol/L) pretreatment enhanced CCh-induced contractions more in mucosa-intact (+MU) than mucosa-denuded (-MU) strips with no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "Wendy works at a chocolate factory packing chocolates.  She can package 2 dozen chocolates in 5 minutes.  How many individual chocolates can she package in 4 hours? \n",
      "Answer:\n",
      "1152 \n",
      "Response:\n",
      "<reasoning>\n",
      "Wendy is packing chocolates and we need to find out how many individual chocolates she can package in 4 hours. \n",
      "\n",
      "First, we'll find out how many chocolates she can package in 1 hour. Since there are 60 minutes in an hour, we start by finding out how many chocolates she can package in 5 minutes and then multiply that by 12 (to get chocolates per hour).\n",
      "\n",
      "Since Wendy can package 2 dozen chocolates (24 chocolates) in 5 minutes, we'll calculate the number of chocolates per 5 minutes:\n",
      "\\[ \\text{Chocolates per 5 minutes \n",
      "Extracted:\n",
      "<reasoning>\n",
      "Wendy is packing chocolates and we need to find out how many individual chocolates she can package in 4 hours. \n",
      "\n",
      "First, we'll find out how many chocolates she can package in 1 hour. Since there are 60 minutes in an hour, we start by finding out how many chocolates she can package in 5 minutes and then multiply that by 12 (to get chocolates per hour).\n",
      "\n",
      "Since Wendy can package 2 dozen chocolates (24 chocolates) in 5 minutes, we'll calculate the number of chocolates per 5 minutes:\n",
      "\\[ \\text{Chocolates per 5 minutes\n",
      "-------------------- Question:\n",
      "Tony has $87. He needs to buy some cheese, which costs $7 a pound and a pound of beef that costs $5 a pound. After buying the beef and his cheese, he has $61 left. How many pounds of cheese did he buy? \n",
      "Answer:\n",
      "3 \n",
      "Response:\n",
      "<reasoning>\n",
      "Tony initially had $87 and he is left with $61 after all purchases. Therefore, he spent $87 - $61 = $26 on his cheese and beef. We know that a pound of beef costs $5. If we let \\( x \\) be the number of pounds of cheese he bought, the cost of cheese would be $7 per pound. For the total expenditure, we can write the equation:\n",
      "\n",
      "\\[5(x = \\text{pounds of beef}) + 7(x = \\text{pounds of cheese}) = 26\\]\n",
      "\n",
      "However, we need \n",
      "Extracted:\n",
      "<reasoning>\n",
      "Tony initially had $87 and he is left with $61 after all purchases. Therefore, he spent $87 - $61 = $26 on his cheese and beef. We know that a pound of beef costs $5. If we let \\( x \\) be the number of pounds of cheese he bought, the cost of cheese would be $7 per pound. For the total expenditure, we can write the equation:\n",
      "\n",
      "\\[5(x = \\text{pounds of beef}) + 7(x = \\text{pounds of cheese}) = 26\\]\n",
      "\n",
      "However, we need\n",
      "-------------------- Question:\n",
      "Bob has to hire someone to fix his garden.  A storm destroyed all 20 of his rose bushes.  He decides to replant all the rose bushes.  Each rose bush costs $150.  He also needs to pay a gardener $30 an hour, 5 hours each day for 4 days.  The final expense is 100 cubic feet of soil sold for $5 per cubic foot.  How much did the entire gardening project cost? \n",
      "Answer:\n",
      "4100 \n",
      "Response:\n",
      "<reasoning>\n",
      "First, let's calculate the cost of replacing all 20 rose bushes. Each rose bush costs $150.\n",
      "\\[ \\text{Cost of rose bushes} = 20 \\times \\$150 = \\$3000 \\]\n",
      "\n",
      "Next, calculate the cost of hiring the gardener. The gardener is paid $30 per hour and works 5 hours each day for 4 days.\n",
      "\\[ \\text{Hourly pay} = \\$30 \\]\n",
      "\\[ \\text{Hours worked per day} = 5 \\]\n",
      "\\[ \\text{Days worked} = 4 \\ \n",
      "Extracted:\n",
      "<reasoning>\n",
      "First, let's calculate the cost of replacing all 20 rose bushes. Each rose bush costs $150.\n",
      "\\[ \\text{Cost of rose bushes} = 20 \\times \\$150 = \\$3000 \\]\n",
      "\n",
      "Next, calculate the cost of hiring the gardener. The gardener is paid $30 per hour and works 5 hours each day for 4 days.\n",
      "\\[ \\text{Hourly pay} = \\$30 \\]\n",
      "\\[ \\text{Hours worked per day} = 5 \\]\n",
      "\\[ \\text{Days worked} = 4 \\\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>profiling/Time taken: GRPOTrainer._calculate_rewards</td><td>█▇▅▁▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer._get_per_token_logps</td><td>█▁▂▁▂▁▁▁▁▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer._prepare_inputs</td><td>█▁▇▁▇▁▇▁▇▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer.compute_loss</td><td>█▁▂▁▂▁▁▁▁▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer.correctness_reward_func</td><td>▆█▃▁▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer.int_reward_func</td><td>▄█▂▁▂</td></tr><tr><td>profiling/Time taken: GRPOTrainer.soft_format_reward_func</td><td>█▃▂▁▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer.strict_format_reward_func</td><td>█▄▂▁▁</td></tr><tr><td>profiling/Time taken: GRPOTrainer.xmlcount_reward_func</td><td>▆█▂▁▁</td></tr><tr><td>train/clip_ratio/high_max</td><td>▁▁▁▁▁</td></tr><tr><td>train/clip_ratio/high_mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/clip_ratio/low_mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/clip_ratio/low_min</td><td>▁▁▁▁▁</td></tr><tr><td>train/clip_ratio/region_mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/clipped_ratio</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/max_length</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/max_terminated_length</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/mean_length</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/mean_terminated_length</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/min_length</td><td>▁▁▁▁▁</td></tr><tr><td>train/completions/min_terminated_length</td><td>▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▃▅▆██</td></tr><tr><td>train/frac_reward_zero_std</td><td>▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁█▇▅▂</td></tr><tr><td>train/loss</td><td>▁▁▁▁▁</td></tr><tr><td>train/num_tokens</td><td>▁▄▅▆█</td></tr><tr><td>train/reward</td><td>██▁▁▁</td></tr><tr><td>train/reward_std</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/correctness_reward_func/mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/correctness_reward_func/std</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/int_reward_func/mean</td><td>██▁▁▁</td></tr><tr><td>train/rewards/int_reward_func/std</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/soft_format_reward_func/mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/soft_format_reward_func/std</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/strict_format_reward_func/mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/strict_format_reward_func/std</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/xmlcount_reward_func/mean</td><td>▁▁▁▁▁</td></tr><tr><td>train/rewards/xmlcount_reward_func/std</td><td>▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>profiling/Time taken: GRPOTrainer._calculate_rewards</td><td>0.00336</td></tr><tr><td>profiling/Time taken: GRPOTrainer._get_per_token_logps</td><td>0.08045</td></tr><tr><td>profiling/Time taken: GRPOTrainer._prepare_inputs</td><td>0.0</td></tr><tr><td>profiling/Time taken: GRPOTrainer.compute_loss</td><td>0.08703</td></tr><tr><td>profiling/Time taken: GRPOTrainer.correctness_reward_func</td><td>0.00116</td></tr><tr><td>profiling/Time taken: GRPOTrainer.int_reward_func</td><td>9e-05</td></tr><tr><td>profiling/Time taken: GRPOTrainer.soft_format_reward_func</td><td>0.00013</td></tr><tr><td>profiling/Time taken: GRPOTrainer.strict_format_reward_func</td><td>0.0001</td></tr><tr><td>profiling/Time taken: GRPOTrainer.xmlcount_reward_func</td><td>0.0001</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/clip_ratio/high_max</td><td>0</td></tr><tr><td>train/clip_ratio/high_mean</td><td>0</td></tr><tr><td>train/clip_ratio/low_mean</td><td>0</td></tr><tr><td>train/clip_ratio/low_min</td><td>0</td></tr><tr><td>train/clip_ratio/region_mean</td><td>0</td></tr><tr><td>train/completions/clipped_ratio</td><td>1</td></tr><tr><td>train/completions/max_length</td><td>128</td></tr><tr><td>train/completions/max_terminated_length</td><td>0</td></tr><tr><td>train/completions/mean_length</td><td>128</td></tr><tr><td>train/completions/mean_terminated_length</td><td>0</td></tr><tr><td>train/completions/min_length</td><td>128</td></tr><tr><td>train/completions/min_terminated_length</td><td>0</td></tr><tr><td>train/epoch</td><td>0.05556</td></tr><tr><td>train/frac_reward_zero_std</td><td>1</td></tr><tr><td>train/global_step</td><td>5</td></tr><tr><td>train/grad_norm</td><td>0</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0</td></tr><tr><td>train/num_tokens</td><td>3026</td></tr><tr><td>train/reward</td><td>0.125</td></tr><tr><td>train/reward_std</td><td>0</td></tr><tr><td>train/rewards/correctness_reward_func/mean</td><td>0</td></tr><tr><td>train/rewards/correctness_reward_func/std</td><td>0</td></tr><tr><td>train/rewards/int_reward_func/mean</td><td>0</td></tr><tr><td>train/rewards/int_reward_func/std</td><td>0</td></tr><tr><td>train/rewards/soft_format_reward_func/mean</td><td>0</td></tr><tr><td>train/rewards/soft_format_reward_func/std</td><td>0</td></tr><tr><td>train/rewards/strict_format_reward_func/mean</td><td>0</td></tr><tr><td>train/rewards/strict_format_reward_func/std</td><td>0</td></tr><tr><td>train/rewards/xmlcount_reward_func/mean</td><td>0.125</td></tr><tr><td>train/rewards/xmlcount_reward_func/std</td><td>0</td></tr><tr><td>train_loss</td><td>0</td></tr><tr><td>train_runtime</td><td>44.3995</td></tr><tr><td>train_samples_per_second</td><td>0.225</td></tr><tr><td>train_steps_per_second</td><td>0.113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-terrain-14</strong> at: <a href='https://wandb.ai/rockbong225-iit-patna/grpo-training/runs/o3cblwsz' target=\"_blank\">https://wandb.ai/rockbong225-iit-patna/grpo-training/runs/o3cblwsz</a><br> View project at: <a href='https://wandb.ai/rockbong225-iit-patna/grpo-training' target=\"_blank\">https://wandb.ai/rockbong225-iit-patna/grpo-training</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250702_183542-o3cblwsz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03154285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "model1 = AutoModelForCausalLM.from_pretrained(model_name,device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce87d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is Aspirin good for cardio vascular function?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fb3a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Aspirin can be beneficial for cardiovascular health, particularly in certain populations and under specific conditions. Here's an overview of its role:\\n\\n1. **Prevention of Thrombosis**: Aspirin is often used to prevent blood clots (thrombosis) in individuals who have had a heart attack or stroke, or who are at high risk of developing such events. It works by inhibiting the production of thromboxane, a substance that helps platelets stick together to form clots.\\n\\n2. **Reduction of Risk in High-Risk Individuals**: For people with a history of cardiovascular disease, aspirin may help reduce the risk of another event. However, this benefit is more pronounced in those who are considered to be at high risk, such as those with diabetes, peripheral artery disease, or a family history of heart disease.\\n\\n3. **Use in Primary Prevention**: While aspirin is sometimes recommended for primary prevention in certain high-risk groups (e.g., those with diabetes or a history of smoking), the decision to use aspirin for this purpose should be carefully discussed with a healthcare provider, as the potential risks (such as bleeding) need to be weighed against the benefits.\\n\\n4. **Side Effects**: Aspirin does carry some risks, including gastrointestinal bleeding and hemorrhagic stroke. These risks increase with higher doses and longer-term use. Therefore, it's important to take aspirin only as prescribed by a doctor.\\n\\n5. **Alternative Approaches**: In recent years, other medications like P2Y12 inhibitors (clopidogrel, prasugrel, ticagrelor) have become more commonly used for primary prevention, especially in combination with low-dose aspirin. These drugs are often preferred because they have fewer gastrointestinal side effects compared to aspirin.\\n\\nIn summary, while aspirin can be beneficial for cardiovascular health, it is generally used in conjunction with other preventive measures and under careful medical supervision. Always consult with a healthcare professional before starting any new medication regimen.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42447bc",
   "metadata": {},
   "source": [
    "##### Check with base model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91fd53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is Aspirin good for cardio vascular function?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = trainer.model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2febd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aspirin can have benefits for cardiovascular health, particularly in certain populations, but it is not without risks and should be used with caution. Here are some key points to consider:\\n\\n### Benefits:\\n1. **Primary Prevention**: For individuals who are at high risk of developing cardiovascular disease (CVD), such as those with a history of heart attack or stroke, or significant coronary artery disease, low-dose aspirin (usually 75-325 mg daily) can reduce the risk of future events.\\n2. **Secondary Prevention**: In patients who have already experienced a heart attack, stroke, or other CVD events, aspirin helps prevent further complications by reducing blood clot formation.\\n\\n### Risks:\\n1. **Gastrointestinal Bleeding**: Aspirin can increase the risk of gastrointestinal bleeding, which is a serious concern, especially in older adults and those with pre-existing conditions like peptic ulcers.\\n2. **Gastrointestinal Irritation**: It may cause stomach pain, nausea, and other gastrointestinal symptoms.\\n3. **Increased Risk of Allergic Reactions**: Some people may experience allergic reactions to aspirin, including asthma exacerbation.\\n4. **Risk of Hemorrhagic Stroke**: High doses of aspirin can increase the risk of hemorrhagic stroke, where bleeding occurs within the brain.\\n\\n### Recommendations:\\n- **Consult Your Doctor**: Before starting or stopping aspirin therapy, you should always consult your healthcare provider. They will consider your overall health, medical history, and other medications you are taking.\\n- **Dose and Duration**: The dose and duration of aspirin therapy depend on individual circumstances and the specific condition being managed.\\n- **Monitoring**: Regular monitoring by a healthcare provider is essential to assess the effectiveness and potential side effects.\\n\\nIn summary, while aspirin can be beneficial for cardiovascular health in specific cases, its use should be carefully considered and monitored due to the associated risks. Always discuss any concerns with your healthcare provider.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
