{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57461b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face token= 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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcb1d9",
   "metadata": {},
   "source": [
    "## Gemma 4b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d36c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 23:39:02.615331: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-17 23:39:02.628723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-17 23:39:02.645264: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-17 23:39:02.650316: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-17 23:39:02.662384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-17 23:39:03.591455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8486fb626b104101b485b48ab49dff80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "import torch\n",
    "# Use gemma-3-4b-it (text-only version)\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "# Load model and processor\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed2a24",
   "metadata": {},
   "source": [
    "#### Logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8d7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_extract_keywords(sentence):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"You are an assistant skilled in logical *persuasion strategy*.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"Extract the *4 to 5 most important single-word keywords* from the following sentence, focusing specifically on the *Logical persuasion strategy*.\n",
    "\n",
    "Return only the keywords as a comma-separated list, with no explanation or extra text.\n",
    "Important: Do not include product names, brand names, place names, or proper nouns.\n",
    "\n",
    " Examples:\n",
    "    Sentence: \"I have a 2021 Honda Amaze. What insurance would you recommend?\"\n",
    "    Output: insurance, recommend\n",
    "\n",
    "    Sentence: \"It includes own damage, third-party liability, theft, natural disasters, and more. The premium is approx $1176 per year, based on IDV.\"\n",
    "    Output: damage, theft, disaster, premium\n",
    "\n",
    "    Sentence: \"This plan provides better coverage and lower premium compared to the previous one.\"\n",
    "    Output: coverage, premium, comparison\n",
    "\n",
    "    Sentence: \"The repair costs are significantly reduced with this policy.\"\n",
    "    Output: repair, cost, policy\n",
    "\n",
    "    Now, extract from the following:\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Prepare input\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "        # Generate output\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(**inputs, max_new_tokens=50, do_sample=False)\n",
    "            output = output[0][input_len:]\n",
    "\n",
    "        # Decode and clean output\n",
    "        decoded = processor.decode(output, skip_special_tokens=True).strip()\n",
    "        keywords = [kw.strip() for kw in decoded.split(\",\") if kw.strip()]\n",
    "        return keywords[:5] + [\"\"] * (5 - len(keywords))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on: {sentence[:40]}... -> {e}\")\n",
    "        return [\"\"] * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce682802",
   "metadata": {},
   "source": [
    "#### Emotinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e530c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotional_extract_keywords(sentence):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are an assistant skilled in *Emotional persuasion strategy* keyword extraction.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"\"\"Extract the *4 to 5 most important single-word keywords* from the following sentence, focusing specifically on the *Emotional persuasion strategy*.\n",
    "\n",
    "Return only the keywords as a comma-separated list, with no explanation or extra text.\n",
    "Important: Do not include product names, brand names, place names, or proper nouns.\n",
    "\n",
    "Focus on words that express emotions, emotional triggers, fears, hopes, desires, or psychological concerns. Avoid factual or neutral terms unless they carry emotional weight.\n",
    "\n",
    "Examples:\n",
    "    Sentence: \"And if I'm in an accident and need a rental car?\"\n",
    "    Output: accident, rental\n",
    "\n",
    "    Sentence: \"For your Jeep Wrangler, it's around $1200 per year. It's an investment in your adventures, knowing you're covered against the unexpected challenges of off-roading.\"\n",
    "    Output: investment, adventures, unexpected, challenges, off-roading\n",
    "\n",
    "    Sentence: \"I've heard about uninsured drivers. What if someone without insurance hits me?\"\n",
    "    Output: uninsured, insurance, hits, fear\n",
    "\n",
    "Now, extract from the following:\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Prepare input\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "        # Generate output\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(**inputs, max_new_tokens=50, do_sample=False)\n",
    "            output = output[0][input_len:]\n",
    "\n",
    "        # Decode and clean output\n",
    "        decoded = processor.decode(output, skip_special_tokens=True).strip()\n",
    "        keywords = [kw.strip() for kw in decoded.split(\",\") if kw.strip()]\n",
    "        return keywords[:5] + [\"\"] * (5 - len(keywords))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on: {sentence[:40]}... -> {e}\")\n",
    "        return [\"\"] * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b71ed",
   "metadata": {},
   "source": [
    "#### Credibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1224127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility_extract_keywords(sentence):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are an assistant skilled in *Emotional persuasion strategy* keyword extraction.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"\"\"Extract the *4 to 5 most important single-word keywords* from the following sentence, focusing specifically on the *Emotional persuasion strategy*.\n",
    "\n",
    "Return only the keywords as a comma-separated list, with no explanation or extra text.\n",
    "Important: Do not include product names, brand names, place names, or proper nouns.\n",
    "\n",
    "Focus on words that express emotions, emotional triggers, fears, hopes, desires, or psychological concerns. Avoid factual or neutral terms unless they carry emotional weight.\n",
    "\n",
    "Examples:\n",
    "    Sentence: \"And if I'm in an accident and need a rental car?\"\n",
    "    Output: accident, rental\n",
    "\n",
    "    Sentence: \"For your Jeep Wrangler, it's around $1200 per year. It's an investment in your adventures, knowing you're covered against the unexpected challenges of off-roading.\"\n",
    "    Output: investment, adventures, unexpected, challenges, off-roading\n",
    "\n",
    "    Sentence: \"I've heard about uninsured drivers. What if someone without insurance hits me?\"\n",
    "    Output: uninsured, insurance, hits, fear\n",
    "\n",
    "Now, extract from the following:\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Prepare input\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "        # Generate output\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(**inputs, max_new_tokens=50, do_sample=False)\n",
    "            output = output[0][input_len:]\n",
    "\n",
    "        # Decode and clean output\n",
    "        decoded = processor.decode(output, skip_special_tokens=True).strip()\n",
    "        keywords = [kw.strip() for kw in decoded.split(\",\") if kw.strip()]\n",
    "        return keywords[:5] + [\"\"] * (5 - len(keywords))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on: {sentence[:40]}... -> {e}\")\n",
    "        return [\"\"] * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac4d02",
   "metadata": {},
   "source": [
    "#### cooperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6ef037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooperative_extract_keywords(sentence):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are an assistant skilled in *Emotional persuasion strategy* keyword extraction.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"\"\"Extract the *4 to 5 most important single-word keywords* from the following sentence, focusing specifically on the *Emotional persuasion strategy*.\n",
    "\n",
    "Return only the keywords as a comma-separated list, with no explanation or extra text.\n",
    "Important: Do not include product names, brand names, place names, or proper nouns.\n",
    "\n",
    "Focus on words that express emotions, emotional triggers, fears, hopes, desires, or psychological concerns. Avoid factual or neutral terms unless they carry emotional weight.\n",
    "\n",
    "Examples:\n",
    "    Sentence: \"And if I'm in an accident and need a rental car?\"\n",
    "    Output: accident, rental\n",
    "\n",
    "    Sentence: \"For your Jeep Wrangler, it's around $1200 per year. It's an investment in your adventures, knowing you're covered against the unexpected challenges of off-roading.\"\n",
    "    Output: investment, adventures, unexpected, challenges, off-roading\n",
    "\n",
    "    Sentence: \"I've heard about uninsured drivers. What if someone without insurance hits me?\"\n",
    "    Output: uninsured, insurance, hits, fear\n",
    "\n",
    "Now, extract from the following:\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Prepare input\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "        # Generate output\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(**inputs, max_new_tokens=50, do_sample=False)\n",
    "            output = output[0][input_len:]\n",
    "\n",
    "        # Decode and clean output\n",
    "        decoded = processor.decode(output, skip_special_tokens=True).strip()\n",
    "        keywords = [kw.strip() for kw in decoded.split(\",\") if kw.strip()]\n",
    "        return keywords[:5] + [\"\"] * (5 - len(keywords))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on: {sentence[:40]}... -> {e}\")\n",
    "        return [\"\"] * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88603a",
   "metadata": {},
   "source": [
    "#### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92284604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_extract_keywords(sentence):\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are an assistant skilled in *Emotional persuasion strategy* keyword extraction.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"\"\"Extract the *4 to 5 most important single-word keywords* from the following sentence, focusing specifically on the *Emotional persuasion strategy*.\n",
    "\n",
    "Return only the keywords as a comma-separated list, with no explanation or extra text.\n",
    "Important: Do not include product names, brand names, place names, or proper nouns.\n",
    "\n",
    "Focus on words that express emotions, emotional triggers, fears, hopes, desires, or psychological concerns. Avoid factual or neutral terms unless they carry emotional weight.\n",
    "\n",
    "Examples:\n",
    "    Sentence: \"And if I'm in an accident and need a rental car?\"\n",
    "    Output: accident, rental\n",
    "\n",
    "    Sentence: \"For your Jeep Wrangler, it's around $1200 per year. It's an investment in your adventures, knowing you're covered against the unexpected challenges of off-roading.\"\n",
    "    Output: investment, adventures, unexpected, challenges, off-roading\n",
    "\n",
    "    Sentence: \"I've heard about uninsured drivers. What if someone without insurance hits me?\"\n",
    "    Output: uninsured, insurance, hits, fear\n",
    "\n",
    "Now, extract from the following:\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Prepare input\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "        input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "        # Generate output\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(**inputs, max_new_tokens=50, do_sample=False)\n",
    "            output = output[0][input_len:]\n",
    "\n",
    "        # Decode and clean output\n",
    "        decoded = processor.decode(output, skip_special_tokens=True).strip()\n",
    "        keywords = [kw.strip() for kw in decoded.split(\",\") if kw.strip()]\n",
    "        return keywords[:5] + [\"\"] * (5 - len(keywords))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on: {sentence[:40]}... -> {e}\")\n",
    "        return [\"\"] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab9bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/rohan_kirti/miniconda3/envs/salesbot/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/DATA/rohan_kirti/miniconda3/envs/salesbot/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:651: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `64` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved to 'gemma_logical_keywords2.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"conversation2.csv\")\n",
    "\n",
    "# Placeholder for extracted keyword rows\n",
    "keywords_list = []\n",
    "\n",
    "# Define a mapping from strategy to its corresponding keyword extraction function\n",
    "strategy_function_map = {\n",
    "    \"logical\": logical_extract_keywords,\n",
    "    \"emotional\": emotional_extract_keywords,\n",
    "    \"credibility\": credibility_extract_keywords,\n",
    "    \"cooperative\": cooperative_extract_keywords,\n",
    "    \"policy\": policy_extract_keywords,\n",
    "}\n",
    "\n",
    "# Process each row and extract keywords\n",
    "for _, row in df.iterrows():\n",
    "    strategy = str(row[\"P-Strategy\"]).strip().lower()\n",
    "    utterance = row[\"utterance\"]\n",
    "    \n",
    "    if strategy in strategy_function_map:\n",
    "        extract_fn = strategy_function_map[strategy]\n",
    "        try:\n",
    "            keywords = extract_fn(utterance)\n",
    "            # Ensure we always get exactly 5 values (pad with empty strings if needed)\n",
    "            keywords = (keywords + [\"\"] * 5)[:5]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {utterance} | Strategy: {strategy} | Error: {e}\")\n",
    "            keywords = [\"\"] * 5\n",
    "    else:\n",
    "        keywords = [\"\"] * 5  # If unknown strategy\n",
    "\n",
    "    keywords_list.append(keywords)\n",
    "\n",
    "# Convert to DataFrame\n",
    "keyword_df = pd.DataFrame(keywords_list, columns=[\"keyword1\", \"keyword2\", \"keyword3\", \"keyword4\", \"keyword5\"])\n",
    "\n",
    "# Merge with original\n",
    "df_with_keywords = pd.concat([df, keyword_df], axis=1)\n",
    "\n",
    "# Save result\n",
    "df_with_keywords.to_csv(\"gema_logical&emotiona_keywords2.csv\", index=False)\n",
    "print(\"✅ Output saved to 'gemma_logical_keywords2.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee31ed",
   "metadata": {},
   "source": [
    "## Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf80f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"conversation.csv\")\n",
    "\n",
    "# Placeholder for extracted keyword rows\n",
    "keywords_list = []\n",
    "\n",
    "# Define a mapping from strategy to its corresponding keyword extraction function\n",
    "strategy_function_map = {\n",
    "    \"logical\": logical_extract_keywords,\n",
    "    \"emotional\": emotional_extract_keywords,\n",
    "    \"credibility\": credibility_extract_keywords,\n",
    "    \"cooperative\": cooperative_extract_keywords,\n",
    "    \"policy\": policy_extract_keywords,\n",
    "}\n",
    "\n",
    "# Process each row and extract keywords\n",
    "for _, row in df.iterrows():\n",
    "    strategy = str(row[\"P-Strategy\"]).strip().lower()\n",
    "    utterance = row[\"utterance\"]\n",
    "    \n",
    "    if strategy in strategy_function_map:\n",
    "        extract_fn = strategy_function_map[strategy]\n",
    "        try:\n",
    "            keywords = extract_fn(utterance)\n",
    "            # Ensure we always get exactly 5 values (pad with empty strings if needed)\n",
    "            keywords = (keywords + [\"\"] * 5)[:5]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {utterance} | Strategy: {strategy} | Error: {e}\")\n",
    "            keywords = [\"\"] * 5\n",
    "    else:\n",
    "        keywords = [\"\"] * 5  # If unknown strategy\n",
    "\n",
    "    keywords_list.append(keywords)\n",
    "\n",
    "# Convert to DataFrame\n",
    "keyword_df = pd.DataFrame(keywords_list, columns=[\"keyword1\", \"keyword2\", \"keyword3\", \"keyword4\", \"keyword5\"])\n",
    "\n",
    "# Merge with original\n",
    "df_with_keywords = pd.concat([df, keyword_df], axis=1)\n",
    "\n",
    "df_with_keywords.to_csv(\"keyword_all.csv\", index=False)\n",
    "print(\"✅ Output saved to 'keyword_all.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
